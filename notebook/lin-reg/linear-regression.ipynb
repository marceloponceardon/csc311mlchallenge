{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe38b595-8f9d-4a51-91d1-03b7f3f2317e",
   "metadata": {},
   "source": [
    "# Linear-Regression Model Exploration (CSC311 Machine Learning Project)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we will explore the linear regression model, using the `sklearn` library.\n",
    "The goal of this exploration is to determine the optimal hyperparameters for our model, and to evaluate the model's performance on the class provided dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff28b5-8831-42f6-911a-81bcccde7dd5",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "\n",
    "For this model I decided to do three different splits on the data\n",
    " 1. 60% Training, 20% Testing, 20% Validation\n",
    " 2. 70% Training, 15% Testing, 15% Validation\n",
    " 3. 80% Training, 10% Testing, 10% Validation\n",
    "\n",
    "Reasoning: from in class experience supported by several online articles (_link articles in footnotes_), it became apparent that having the largest subset of the data devoted just for training was necessary.\n",
    "\n",
    "Then, having _N = 1440_ data points, that gives us:\n",
    " 1. `n_train, n_test, n_valid = 0.6 * N, 0.2 * N, 0.2 * N`\n",
    " 2. `n_train, n_test, n_valid = 0.7 * N, 0.15 * N, 0.15 * N`\n",
    " 3. `n_train, n_test, n_valid = 0.8 * N, 0.1 * N, 0.1 * N`\n",
    "\n",
    "The data is split in the following way (this is implemented in `/model/encoding.py` in `data_split()`:\n",
    "- `x_test, y_test = x[:n_train], y[:n_train]`\n",
    "- `x_train, y_train = x[n_train:n_train + n_test], y[n_train:n_train + n_test]`\n",
    "- `x_valid, y_valid = x[n_train + n_test:], y[n_train + n_test]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456f83c5-8e65-4b11-8fe9-92f697f93917",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb9b9e-1358-4f14-aba8-f080f6e4df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../') # Path to root directory\n",
    "\n",
    "from model.encoding import encode, split_data\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "FILE_NAME = \"clean_dataset.csv\"\n",
    "FILE_PATH = \"../../model/\"\n",
    "\n",
    "# Encode the data\n",
    "X, t = encode(FILE_PATH + FILE_NAME)\n",
    "print(\"Number of data points: \" + str(x.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "504db480-99aa-40c0-af2c-aaa76878ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(splits=[(0.6, 0.2), (0.7, 0.15), (0.8, 0.1), (0.9, 0.05), (0.95, 0.025)]):\n",
    "    for split in splits:\n",
    "        # Split the data\n",
    "        print(\"\\tSplit:\", split)\n",
    "        X_train, t_train, X_test, t_test, X_valid, t_valid = split_data(X, t, split[0], split[1])\n",
    "        \n",
    "        # Print in a nice format\n",
    "        print(f\"Training data: {X_train.shape[0]} samples\")\n",
    "        print(f\"Testing data: {X_test.shape[0]} samples\")\n",
    "        print(f\"Validation data: {X_valid.shape[0]} samples\")\n",
    "        \n",
    "        # Fit, train and test\n",
    "        linreg = LR(fit_intercept = False)\n",
    "        linreg.fit(X_train, t_train)\n",
    "        \n",
    "        y_train_pred = linreg.predict(X_train)\n",
    "        y_test_pred = linreg.predict(X_test)\n",
    "        y_valid_pred = linreg.predict(X_valid)\n",
    "        \n",
    "        # Calculate mse for training and testing predicions\n",
    "        train_mse = mse(t_train, y_train_pred)\n",
    "        test_mse = mse(t_test, y_test_pred)\n",
    "        valid_mse = mse(t_valid, y_valid_pred)\n",
    "        \n",
    "        # print(linreg.coef_) # weights\n",
    "        print(\"\\t\\tTraining MSE:\", train_mse)\n",
    "        print(\"\\t\\tTesting MSE:\", test_mse)\n",
    "        print(\"\\t\\tValidation MSE:\", valid_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "04aae890-f411-48db-96d0-2eeca895a626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSplit: (0.6, 0.2)\n",
      "Training data: 880 samples\n",
      "Testing data: 293 samples\n",
      "Validation data: 295 samples\n",
      "\t\tTraining MSE: 0.05380860790365482\n",
      "\t\tTesting MSE: 0.5629065305453214\n",
      "\t\tValidation MSE: 51.332363194031785\n",
      "\tSplit: (0.7, 0.15)\n",
      "Training data: 1027 samples\n",
      "Testing data: 220 samples\n",
      "Validation data: 221 samples\n",
      "\t\tTraining MSE: 0.06427158602302369\n",
      "\t\tTesting MSE: 0.7265653181467783\n",
      "\t\tValidation MSE: 0.07251590801827494\n",
      "\tSplit: (0.8, 0.1)\n",
      "Training data: 1174 samples\n",
      "Testing data: 146 samples\n",
      "Validation data: 148 samples\n",
      "\t\tTraining MSE: 0.0641254242836685\n",
      "\t\tTesting MSE: 1.2763779565186741\n",
      "\t\tValidation MSE: 0.06821763648267096\n",
      "\tSplit: (0.9, 0.05)\n",
      "Training data: 1321 samples\n",
      "Testing data: 73 samples\n",
      "Validation data: 74 samples\n",
      "\t\tTraining MSE: 0.06595748219133354\n",
      "\t\tTesting MSE: 0.06259121488700696\n",
      "\t\tValidation MSE: 0.07745315543323072\n",
      "\tSplit: (0.95, 0.025)\n",
      "Training data: 1394 samples\n",
      "Testing data: 36 samples\n",
      "Validation data: 38 samples\n",
      "\t\tTraining MSE: 0.06539519485981833\n",
      "\t\tTesting MSE: 0.09179759042452822\n",
      "\t\tValidation MSE: 0.06311654290086624\n"
     ]
    }
   ],
   "source": [
    "process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770ff3c-1fd6-4503-abae-55ad464eb672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
